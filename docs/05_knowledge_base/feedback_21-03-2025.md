---
title: "FEEDBACK 21-03-2025"                             # CHANGE IF NEEDED
subtitle: "FISIO FIND - Grupo 6 - #SPRINT 2"
author: [Alberto Carmona Sicre, Antonio Macías Ferrera, Benjamín Ignacio Maureira Flores, Francisco Capote García, Daniel Alors Romero, Daniel Fernández Caballero, Daniel Ruiz López, Daniel Tortorici Bartús, Daniel Vela Camacho, Delfín Santana Rubio, Guadalupe Ridruejo Pineda, Julen Redondo Pacheco, Miguel Encina Martínez, Francisco Mateos Villarejo, Pablo Fernández Pérez, Ramón Gavira Sánchez, Rafael Pulido Cifuentes]
date: "23/03/2025"                                       # CHANGE IF NEEDED
subject: "ISPP"
lang: "es"
toc: true
titlepage: true
titlepage-text-color: "1C1C1C"
titlepage-rule-color: "1C1C1C"
titlepage-rule-height: 0
colorlinks: true
linkcolor: blue
titlepage-background: "../.backgrounds/background2V.pdf" # CHANGE IF NEEDED
header-left: "FEEDBACK"                                  # CHANGE IF NEEDED
header-right: "23/03/2025"                               # CHANGE IF NEEDED
footer-left: "FISIO FIND"
documentclass: scrartcl
classoption: "table"  
---

<!-- COMMENT THIS WHEN EXPORTING TO PDF -->
<p align="center">
  <img src="../.img/Logo_FisioFind_Verde_sin_fondo.webp" alt="Logo FisioFind" width="300" />
</p>

<h1 align="center" style="font-size: 30px; font-weight: bold;">
  FISIO FIND  -  FEEDBACK 21-03-2025
</h1>

<br>


**ÍNDICE**
- [**1. RESUMEN DEL FEEDBACK POR GRUPO**](#1-resumen-del-feedback-por-grupo)
  - [**Primer grupo (Holos):**](#primer-grupo-holos)
  - [**Segundo grupo (Gastrostock):**](#segundo-grupo-gastrostock)
  - [**Tercer grupo (Eventbride):**](#tercer-grupo-eventbride)
  - [**Cuarto grupo (BORROO):**](#cuarto-grupo-borroo)
  - [**Quinto grupo (CAMYO):**](#quinto-grupo-camyo)
  - [**Sexto grupo (FISIO FIND):**](#sexto-grupo-fisio-find)
- [**2. ANÁLISIS DEL FEEDBACK**](#2-análisis-del-feedback)
  - [**2.1. TENDENCIAS GENERALES**](#21-tendencias-generales)
  - [**2.2. COMPARACIÓN DEL FEEDBACK DE NUESTRO GRUPO VS LOS OTROS**](#22-comparación-del-feedback-de-nuestro-grupo-vs-los-otros)
  - [Discusión para la siguiente clase.](#discusión-para-la-siguiente-clase)
      - [PRÓXIMA SEMANA](#próxima-semana)
- [**3. CONCLUSIONES Y OBSERVACIONES**](#3-conclusiones-y-observaciones)
<!-- COMMENT WHEN EXPORTING TO PDF -->

<br>


---

**Ficha del documento**

- **Nombre del Proyecto:** FISIO FIND

- **Número de Grupo:** Grupo 6

- **Entregable:** #SPRINT 2

- **Miembros del grupo:** Alberto Carmona Sicre, Antonio Macías Ferrera, Benjamín Ignacio Maureira Flores, Francisco Capote García, Daniel Alors Romero, Daniel Fernández Caballero, Daniel Ruiz López, Daniel Tortorici Bartús, Daniel Vela Camacho, Delfín Santana Rubio, Guadalupe Ridruejo Pineda, Julen Redondo Pacheco, Miguel Encina Martínez, Francisco Mateos Villarejo, Pablo Fernández Pérez, Ramón Gavira Sánchez, Rafael Pulido Cifuentes.

- **Contribuidores:** [Alberto Carmona Sicre](https://github.com/albcarsic) (autor)

- **Fecha de Creación:** 23/03/2025  

- **Versión:** v1.0

<br>


---

<!-- \newpage -->

**Histórico de Modificaciones**

| Fecha      | Versión | Realizada por          | Descripción de los cambios                 |
| ---------- | ------- | ---------------------- | ------------------------------------------ |
| 23/03/2025 | v1.0    | Alberto Carmona Sicre | Primera versión del documento |

<br>

<!-- \newpage -->

<br>


# **1. RESUMEN DEL FEEDBACK POR GRUPO**

## **Primer grupo (Holos):**
**Feedback alumnos**

- Buen inicio efectivo.

- El GDPR está muy bien descrito.
 
**Feedback recibido (resumen de los comentarios de los profesores)**

- En el inicio efectivo no quedaba claro quién era el cliente. No se ha enfocado bien al publico de la presentación, ya que nosotros seríamos un público “usuario” y no un público “artista”. Además, debería ser más específico, para que no se pierda tiempo.

- En Costes, las licencias.

- La gráfica para los costes incurridos no es intuitiva.

- La demo se veía y se oía bien. Sobre todo se entendía bien, mostraba un CU fácil de seguir.

- Las soluciones son propuestas, no son compromisos.

- Pequeño fallo: hasta ahora no tenían Github Project.

- En cumplimiento de plazos poner claramente si alguien ha sido marcado por no cumplir con plazos.

- En el apartado de IA, no parece que esté bien planteado porque actualmente no hay formas de detectar si se usa o no.

- Los costes tienen defectos que deberían corregirse.

**Puntos positivos destacados**

- Buena demo.

**Áreas de mejora sugeridas**

- Mejorar costes y licencias.

- Inicio efectivo más específico.

- Replantear cómo se detecta el uso de IAs.

<br>

## **Segundo grupo (Gastrostock):** 
**Feedback alumnos**:

- Buen inicio efectivo.

- Responden al feedback explicando correctamente la funcionalidad y los distintos dispositivos donde quieren desplegar/hacer una app.

- Siguen poniendo las cifras de precios sin Ks.

**Feedback recibido (resumen de los comentarios de los profesores)**

- Tiene que apoyar las cosas que dice en información cuantitativa que evidencie lo dicho y que sea fácil de entender (que permita saber si es creíble, etc). No es recomendable que el público tenga que dejar de atender para calcular/entender los datos.

- Buen inicio efectivo, pero un poco largo.

- Ha empezado con mucha energía, pero un poco monótono.

- En el gráfico de costes, poner colores que tengan un significado estándar. Por ejemplo, no poner una línea de valoración pesimista en verde, cuando este se suele usar para indicar beneficios.

- La demo es bastante mejorable.

- Los anuncios no se ven bien.

- Rendimiento del equipo, problemas encontrados, storyboard no han puesto.

**Puntos positivos destacados**

- Buen inicio efectivo.

**Áreas de mejora sugeridas**

- Apoyarse en datos.

- Colores en las gráficas con sentido, aunque pueda parecer una tontería.

- Demo mejorable.

- Faltan métricas cuantitativas de calidad.

<br>

## **Tercer grupo (Eventbride):** 
**Feedback alumnos**

- Inicio efectivo chulo. 

- Dos tardes haciendo el storyboard.

- Muy informal la demo.

- No se ve muy bien la demo, pero parece que va al target.

**Feedback recibido (resumen de los comentarios de los profesores)**

- Deberían usar un aparato para cambiar de diapositiva.

- Muy buena conexion entre killer openers.

- No hacer referencia a las semanas pasadas.

- Buen desarrollo de los storyboards (a mano, directos, claros, no demasiadas escenas).

- Parece que no es multievento en la presentación.

- Mostrar más claramente las líneas de corte de los costes.

- Equipo: no está puesto el responsable de GDPR.

- Muy buena demo. Se escuchaba alto y claro, se definían bien los roles y era relativamente cómico. Quizás mejorar la experiencia de usuario.

- Destacar el workflow.

- Hay que ser capaz de medir las soluciones.

- Es necesario una gráfica de barras para mostrar la evolución cuantitativa del rendimiento del equipo.

**Puntos positivos destacados**

- Buena conexión entre killers openers.

- Muy buena demo.

- Workflow destacable.

- Muy buenos storyboards.

**Áreas de mejora sugeridas**

- Mostrar mejor las líneas de corte de los costes.

- Mejorar la experiencia de usuario en la demo (que se vea bien).

- Soluciones medibles.

- Gráfica de barras de evolución cuantitativa del rendimiento del equipo.

<br>

## **Cuarto grupo (BORROO):** 
**Feedback alumnos**

- Muy buena esa comparación entre las gráficas "burn down".

- Han mejorado mucho la forma de presentación, ahora tiene un ritmo más calmado.

**Feedback recibido (resumen de los comentarios de los profesores)**

- Personajes poco acertados en la demo y el killer opener.

- Pequeño fallo: ponen mil en vez de k para representar cifras grandes.

- En las gráficas de costes, es importante poner de dónde salen los números, porque el público se va a preguntar si es realista. Se tiene que poner el número de usuarios/transacciones en cada punto.

- Los usuarios piloto deberían probar la aplicación. Tienen que poner su valor diferencial y lo que valoran los usuarios piloto.

- Muchas cosas que han dicho no están apoyadas en datos cuantitativos.

- Han puesto dos storyboards, pero parecen poco ocurrentes (expresión literal).

- La demo se puede poner más grande.

- Diapositiva de IA poco genérica. Solo había tres textos. Se podría haber puesto de herramientas usadas, métricas… Faltan más transparencias en este apartado.

- No se deben hacer afirmaciones absolutas que se apliquen a todos los proyectos sin excepción.

- Han mejorado la presentación poniendo títulos en todas las diapositivas.

- Es importante detallar más el proceso de evaluación del rendimiento individual del equipo.

**Puntos positivos destacados**

- Han mejorado la presentación poniendo títulos en todas las diapositivas.

**Áreas de mejora sugeridas**

- Buscar personajes adecuados para el killer opener y la demo.

- Usar la k en los costes.

- Poner de dónde salen los números en las gráficas de costes.

- Que los usuarios piloto prueben la app.

- Apoyarse en datos cuantitativos.

- Los storyboards son poco ocurrentes.

- Más diapositivas de IA.

- Detallar el proceso de evaluación del rendimiento individual del equipo.

<br>

## **Quinto grupo (CAMYO):** 
**Feedback alumnos**:

- Buen inicio efectivo como si fuera un simulacro de incendios.

- Se ha equivocado un poco al explicar los derechos sobre los datos.

- Muy bien el top 3 de rendimiento semanal.

**Feedback recibido (resumen de los comentarios de los profesores)**

- El principio muy rápido. Parece casi que no ha dicho el elevator pitch. Quizás ha sido por los problemas técnicos iniciales.

- ¿A quién va dirigido el storyboard? Parece que va a varios targets y eso puede hacer que no funcione. Debería ser dirigido a solo un target.

- Muy buen killer opener por lo de la alarma, ha captado la atención completamente. Sin embargo, ha faltado que conecte con la demo.

- El impacto legal está muy bien, tanto las conclusiones como lo que afecta al usuario.

- CapEx y OpEx están bien.

- Falta una gráfica de corte para mostrar cuándo se empieza a ganar más de lo que se gasta.

- ¿Han priorizado el feedback? 

	- Está en proceso de priorización porque es reciente.

- En la gestión de usuarios piloto han dicho muchas cosas sin apoyo visual. Hace falta apoyo (seguramente será porque es reciente).

- Además del QR, poner un email de contacto.

- La demo se escucha poco y se ve poco. 

- Una propuesta de mejora es que los audios en las demos sean grabados por varias personas, para identificar aun mejor cuando se cambie entre distintos usuarios.

- No han dicho ningún problema. Parece que es porque no hay ninguno.

	- Esta semana están probando una solución, por lo que no saben si está funcionando o no.

- La trasparencia de historias de usuario tiene demasiada incertidumbre, porque depende de los últimos dias del sprint.

**Puntos positivos destacados**

- Buena captación de atención en el killer opener.

- Muy bien definido el impacto legal.

- Bien el CapEx y el OpEx.

**Áreas de mejora sugeridas**

- Principio demasiado rápido.

- Dirigir el storyboard a un solo target.

- Falta una gráfica de corte para mostrar cuándo se empieza a ganar más de lo que se gasta.

- Usar apoyo visual.

- Demo mejorable audiovisualmente. Además de añadir distintas voces.

- No se ha hablado expresamente de problemas/soluciones/estado.

<br>

## **Sexto grupo (FISIO FIND):** 
**Feedback alumnos**

- Muy chulo el inicio efectivo.

- Dani habla un poco bajo.

- La demo no se ve nada.

- Los números en la dedicación individual no se ven bien.

**Feedback recibido (resumen de los comentarios de los profesores)**

- Dani debería hablar con más fuerza.

- Buen inicio efectivo destacando que NO existe en el mercado y por qué nos diferenciamos. Complementando al anuncio de la semana anterior.

- Han respondido al feedback del killer opener.

- Los competidores deben pasar más rápido.

- Revisar qué es una RfC (debe ser una petición que realiza un usuario para cambiar o añadir funcionalidad).

- Buen guiño a las píldoras teóricas.

- Quizás se deberían usar otras gráficas que se dieron en otras asignaturas.

- La gráfica sobre tareas realizadas debería ser de barras, en lugar de área.

- La demo se veía muy pequeña, debería tener audio incluido (diferenciando por rol), los títulos de cada funcionalidad deberían ser estáticos y pequeños que se deberían mostrar más tiempo.

- Muy bien el canal de denuncias.

- ¿Como miden el rendimiento del equipo? Deberian poner cómo se hace. Además de mostrar una gráfica.

- Detallar un poco más la gráfica de evaluación de la calidad.

- Sistema de recompensas: hay que intentar buscar un sistema que no cueste dinero. Por ejemplo, que elija la tarea.

- Añadir apartado de evolución de los problemas (problema -> métrica -> objetivo -> estado).

- Algunas métricas son objetivos. 

- Se ha mejorado estéticamente la presentación.

- En costes, falta indicar qué porcentaje de fisios tienen qué plan.

**Puntos positivos destacados**

- Buen inicio efectivo.

- Bien el canal de denuncias.

- Mejora estética de la presentación.

**Áreas de mejora sugeridas**

- Los competidores deben pasar más rápido.

- Revisión de las RfC.

- Hacer uso de otras gráficas.

- Demo mejorable. Que sea más grande y se usen distintas voces para distintos roles.

- Añadir más información sobre el rendimiento del equipo.

- Buscar un sistema de recompensas que no cueste dinero.

- Añadir apartado de evolución de los problemas.

- En costes, indicar cuánto porcentaje de fisios tienen qué plan.

<br>


# **2. ANÁLISIS DEL FEEDBACK**

## **2.1. TENDENCIAS GENERALES**
**Factores comunes en los comentarios de los profesores**

- Inicio efectivo: La mayoría de los grupos han logrado captar la atención del público al inicio, aunque en algunos casos fue demasiado largo o no se conectó con la demo.

- Necesidad de apoyo cuantitativo: Muchos equipos hicieron afirmaciones sin sustentarlas con datos claros o gráficas comprensibles.

- Gráficas mejorables: Hay errores frecuentes en el diseño o uso de gráficas, como colores mal elegidos, falta de contexto, o formatos poco intuitivos.

- Demos poco visibles o poco audibles: Es una queja generalizada. En varios casos, no se ve bien la demo o no se escucha, o es mejorable la diferenciación de los roles.

- Evaluación del rendimiento del equipo poco detallada: Varios grupos no explican claramente cómo miden el rendimiento, o bien no lo representan visualmente.

**Puntos de fortaleza general en los equipos**

- Buenos killer openers en general, creativos y capaces de captar la atención.

- Algunas presentaciones han mejorado estética y estructuralmente con respecto a semanas anteriores.

- En varios grupos, el impacto legal o la gestión de privacidad (como el GDPR) se ha tratado con seriedad y claridad.

**Áreas de mejora recurrentes**

- Demo técnica: Mejorar su visibilidad, calidad de audio y claridad del caso de uso.

- Justificación de costes: Muchos grupos deben explicar mejor el origen de los datos económicos y cómo se proyectan.

- Más métricas y datos: Se necesita un mayor uso de datos cuantitativos, tanto en resultados como en la presentación de problemas y soluciones.

- Evaluación del rendimiento del equipo: Hacer más visible y clara esta parte, con gráficos u otros sistemas que muestren progreso.

- Uso de IA y métricas: Apartado generalmente débil, con poca profundidad y escasa presentación visual o analítica.

<br>

## **2.2. COMPARACIÓN DEL FEEDBACK DE NUESTRO GRUPO VS LOS OTROS**

**¿Qué estamos haciendo bien en comparación con otros?**

- Inicio efectivo claro y diferenciador: Se destacó positivamente la introducción, por presentar de forma contundente que no hay una solución similar en el mercado, y complementar con el anuncio de la semana anterior.

- Canal de denuncias: Es un elemento muy valorado que no se ha mencionado en otros equipos.

- Impacto legal bien trabajado: Al igual que algún otro grupo, se ha abordado con claridad la parte legal y cómo afecta al usuario, lo cual no es un estándar en todos los equipos.

- Mejora estética de la presentación: Se ha notado una evolución positiva en la parte visual, lo que ha sido reconocido.

- Respuesta al feedback anterior: Se ha trabajado conscientemente en incorporar sugerencias previas.

**¿Qué aspectos debemos mejorar respecto a los demás?**

- Demo: Aunque algunos grupos también han tenido problemas aquí, en nuestro caso la demo se ve muy pequeña y no incluye voces diferenciadas por rol. Otros grupos han logrado una demo más clara y comprensible.

- Datos de rendimiento del equipo: Falta detallar mejor cómo se mide y presentar alguna gráfica que lo represente.

- Presentación de problemas y evolución: Hay que incluir un apartado claro con problemas, métricas asociadas, objetivos y estado actual.

- Gráficas: Aún podemos mejorar el tipo de gráficas usadas (como reemplazar áreas por barras cuando corresponde) y hacerlas más intuitivas, algo que también se ha señalado en muchos grupos.

- Porcentaje de planes en los costes: Es un detalle importante no incluido aún y que aportaría claridad a la sostenibilidad del modelo.

<br>

## Discusión para la siguiente clase.

- La próxima semana la presentación deberá tener más o menos lo mismo.

- Se aconseja tener un calendario compartido para las reuniones.

- Se recomienda tener changelog.

- Hay que hacer acuerdo de usuario piloto con los usuarios de la asignatura.

#### PRÓXIMA SEMANA

- Introducción:

	- Killer oppener de 1 minuto.

	- Elevator pitch de 30 segundos.

	- Presentar los competidores más al grano.

	- Storyboard de otro target (inversor mejor no).

	- Customer agreement, licencias, términos y condiciones del servicio, evitar clausulas abusivas, acuerdos de nivel de servicio, implicaciones otras apis, pricing, gdpr.

	- TCO, CapEx OpEx, github, optimista, realista y pesimista. Mejorar con el feedback dado.

	- Equipo igual: resumen, roles, commitment agreement status (ver si se esta cumpliendo).

- Demo

	- Mejorar la calidad visual y auditiva, así como una buena diferenciación de roles: usar distintas voces si hay distintos usuarios.

- Retrospectiva 40%-50%

	- Casi lo mismo.

	- Añadir gráficas rendimiento/esfuerzo: Mucho esfuerzo poco rendimiento, poco esfuerzo mucho rendimiento, etc.

	- Gráficas rendimiento personal, análisis software.

	- En el apartado de Problemas igual pero decir, además del problema, el estado de este (si es de antes, solucionado, no solucionado, etc), las acciones concretas y ver alguna forma de evaluar esa solución. Analizar las soluciones. Añadir unas lecciones aprendidas del análisis.

- Gestión de usuarios piloto: Nada nuevo parece.

	- Gestión del feedback, comunicación.

- Replanificación:

	- Sprint 3, aspectos de seguridad (validación de los formularios, correos). Ver si la validación de correos tiene repercusión en el OpEx.

- Uso IA:

	- Decir que si se ha mejorado el uso de la IA desde el principio, lecciones aprendidas, alucionaciones. 

	- Evitar cosas genéricas.


# **3. CONCLUSIONES Y OBSERVACIONES**

- Nuestra presentación ha sido valorada positivamente por su estética y por haber respondido al feedback previo, pero debemos seguir trabajando en la proyección de voz y en asegurar que todos los miembros del equipo se escuchen con claridad durante la exposición.

- El killer opener ha sido bien recibido por su originalidad y capacidad de diferenciación, destacando la ausencia de soluciones similares en el mercado. Aun así, se sugiere trabajar una mejor conexión entre esa introducción y la demo, para que el hilo narrativo sea más fluido.

- Se ha valorado positivamente nuestro enfoque en el canal de denuncias y el impacto legal del proyecto, dos apartados que no han sido tan desarrollados por otros equipos. Debemos mantener esta línea e incluso reforzarla como un valor diferencial.

- La demo ha sido uno de los puntos más débiles. Es necesario aumentar su tamaño visual, mejorar el audio y añadir voces diferenciadas según los roles. Además, los títulos deben mostrarse de forma clara y constante para facilitar la comprensión del caso de uso.

- Aunque se reconocen nuestros esfuerzos por incluir métricas, se nos ha recomendado mejorar el tipo de gráficas utilizadas, optando por formatos más adecuados como barras en vez de áreas para representar tareas o rendimiento.

- El sistema de recompensas necesita ser replanteado. En lugar de implicar costes, podemos explorar alternativas motivadoras como permitir que el miembro destacado elija tareas o influya en decisiones del equipo.

- Nos falta mostrar con más claridad cómo se mide el rendimiento del equipo. Incluir una gráfica específica y explicar el proceso de evaluación ayudaría a demostrar mejor nuestra organización interna.

- Es importante que incorporemos un apartado visual sobre la evolución de los problemas del proyecto, mostrando cómo estos se identifican, cómo se miden, qué objetivos se fijan y cuál es su estado actual. Esto no solo mejora la transparencia, sino también nuestra capacidad de reacción ante imprevistos.

- En el apartado de costes, debemos especificar el porcentaje de fisioterapeutas que se espera que adopten cada tipo de plan, para dar mayor realismo y credibilidad al modelo de negocio.


<br>

---

**Aprobado por:**  
**Scrum Master:** Antonio Macías Ferrera  
**Secretario:** Alberto Carmona Sicre
